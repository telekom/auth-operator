# SPDX-FileCopyrightText: 2026 Deutsche Telekom AG
#
# SPDX-License-Identifier: Apache-2.0

name: Output Delta

on:
  pull_request:
    branches: [main]
    paths:
      - 'api/**'
      - 'internal/**'
      - 'pkg/**'
      - 'config/samples/**'
      - 'go.mod'
      - 'go.sum'

permissions:
  contents: read
  pull-requests: write

env:
  GO_VERSION: "1.25.7"
  KIND_VERSION: "v0.31.0"

jobs:
  output-delta:
    name: Generate Output Delta
    runs-on: ubuntu-latest
    steps:
      - name: Checkout PR branch
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          path: pr-branch
          fetch-depth: 0 # Needed to fetch tags

      - name: Checkout main branch
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: main
          path: main-branch

      - name: Get latest release tag
        id: latest-tag
        run: |
          cd pr-branch
          LATEST_TAG=$(git tag -l 'v*.*.*' 2>/dev/null | sort -V | tail -1 || echo "")
          if [ -n "$LATEST_TAG" ]; then
            if git rev-parse "$LATEST_TAG" >/dev/null 2>&1; then
              echo "tag=$LATEST_TAG" >> $GITHUB_OUTPUT
              echo "has_tag=true" >> $GITHUB_OUTPUT
              echo "Latest release tag (by semver): $LATEST_TAG"
            else
              echo "::warning::Tag $LATEST_TAG exists but is not reachable, skipping tag comparison"
              echo "has_tag=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "::notice::No release tags found (looking for v*.*.* pattern), skipping tag comparison"
            echo "has_tag=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout latest tag
        if: steps.latest-tag.outputs.has_tag == 'true'
        id: checkout-tag
        continue-on-error: true
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ steps.latest-tag.outputs.tag }}
          path: tag-branch

      - name: Setup Go Environment
        uses: ./pr-branch/.github/actions/setup-go-env
        with:
          go-version: ${{ env.GO_VERSION }}
          install-kind: 'true'
          kind-version: ${{ env.KIND_VERSION }}
          cache-dependency-path: pr-branch/go.sum

      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq

      - name: Create kind cluster
        run: |
          kind create cluster --name output-delta --wait 5m
          kubectl cluster-info

      - name: Install popular CRDs
        run: |
          KIND_CLUSTER_NAME=output-delta bash pr-branch/hack/ci/setup-kind-crds.sh

      - name: Create test namespaces
        run: bash pr-branch/hack/ci/create-test-namespaces.sh

      # =====================================================================
      #  Main branch
      # =====================================================================
      - name: Generate outputs from main branch
        id: main-output
        continue-on-error: true
        run: |
          cd main-branch

          # Build and load the operator image
          make docker-build IMG=auth-operator:main
          kind load docker-image auth-operator:main --name output-delta

          # Install CRDs
          make install

          # Deploy the operator
          make deploy IMG=auth-operator:main
          echo "Waiting for operator to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=controller-manager -A 2>/dev/null || \
            echo "::warning::Could not verify controller-manager readiness, continuing anyway"

          # Wait for webhook server if deployed (required for BindDefinition validation)
          echo "Waiting for webhook server to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=webhook-server -A 2>/dev/null || \
            echo "::notice::Webhook server not found or not ready, continuing anyway"
          sleep 5

          # Try to apply sample configs with retry -- may fail if main branch samples are incompatible
          main_samples_applied=false
          for i in 1 2 3 4 5; do
            if kubectl apply --server-side --force-conflicts -k config/samples/ 2>&1; then
              main_samples_applied=true
              break
            fi
            echo "Attempt $i failed, waiting before retry..."
            sleep 10
          done
          echo "main_samples_applied=${main_samples_applied}" >> $GITHUB_OUTPUT
          if [ "$main_samples_applied" = "false" ]; then
            echo "::warning::Main branch samples failed to apply, will use PR branch samples as baseline"
          fi

          # Wait for all CRs to be fully reconciled (Ready condition)
          echo "Waiting for resources to be reconciled..."
          kubectl wait --for=condition=Ready roledefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some RoleDefinitions not fully reconciled"
          kubectl wait --for=condition=Ready binddefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some BindDefinitions not fully reconciled"

          # Capture generated resources (yq strips volatile K8s internal fields)
          bash ../pr-branch/hack/ci/capture-operator-output.sh /tmp/main-output

          # Cleanup samples -- delete CRs and wait for finalizers to be processed before undeploying
          kubectl delete -k config/samples/ --ignore-not-found --timeout=60s 2>/dev/null || true
          echo "Waiting for CRs to be fully deleted..."
          kubectl wait --for=delete roledefinition --all --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete binddefinition --all --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete webhookauthorizer --all --timeout=60s 2>/dev/null || true
          make undeploy 2>/dev/null || true

          echo "Main branch outputs captured"

      # =====================================================================
      #  Fallback baseline (uses PR branch when main fails)
      # =====================================================================
      - name: Fallback - use PR samples for main baseline
        if: steps.main-output.outputs.main_samples_applied == 'false' || steps.main-output.outcome == 'failure'
        run: |
          echo "::notice::Using PR branch samples as baseline since main branch samples failed to apply"
          cd pr-branch

          make docker-build IMG=auth-operator:pr
          kind load docker-image auth-operator:pr --name output-delta

          make deploy IMG=auth-operator:pr
          kubectl wait --for=condition=available --timeout=180s deployment -l control-plane=controller-manager -A 2>/dev/null || \
            echo "::warning::Controller-manager deployment not Available in time (fallback baseline will continue anyway)"

          echo "Waiting for webhook server to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=webhook-server -A 2>/dev/null || \
            echo "::warning::Webhook server not ready in time, continuing anyway"
          sleep 5

          # Apply PR samples to generate baseline with retry
          for i in 1 2 3 4 5; do
            if kubectl apply --server-side --force-conflicts -k config/samples/ 2>&1; then
              echo "Samples applied successfully"
              break
            fi
            echo "Attempt $i failed, waiting before retry..."
            sleep 10
          done

          # Wait for reconciliation
          kubectl wait --for=condition=Ready roledefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some RoleDefinitions not fully reconciled"
          kubectl wait --for=condition=Ready binddefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some BindDefinitions not fully reconciled"

          bash hack/ci/capture-operator-output.sh /tmp/main-output

          kubectl delete -k config/samples/ --ignore-not-found --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete roledefinition --all --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete binddefinition --all --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete webhookauthorizer --all --timeout=60s 2>/dev/null || true
          make undeploy 2>/dev/null || true

          echo "Fallback baseline captured using PR branch samples"
          echo "MAIN_FALLBACK=true" >> $GITHUB_ENV

      # =====================================================================
      #  Latest release tag
      # =====================================================================
      - name: Generate outputs from latest tag
        id: tag-output
        if: steps.latest-tag.outputs.has_tag == 'true' && steps.checkout-tag.outcome == 'success'
        continue-on-error: true
        run: |
          if [ ! -d "tag-branch" ]; then
            echo "::warning::Tag checkout failed, skipping tag comparison"
            echo "tag_success=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          cd tag-branch

          make docker-build IMG=auth-operator:tag 2>/dev/null || {
            echo "::warning::Failed to build tag version (${{ steps.latest-tag.outputs.tag }}), skipping tag comparison"
            echo "tag_success=false" >> $GITHUB_OUTPUT
            exit 0
          }
          kind load docker-image auth-operator:tag --name output-delta

          make install 2>/dev/null || true

          make deploy IMG=auth-operator:tag 2>/dev/null || {
            echo "::warning::Failed to deploy tag version, skipping tag comparison"
            echo "tag_success=false" >> $GITHUB_OUTPUT
            exit 0
          }
          echo "Waiting for operator to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=controller-manager -A 2>/dev/null || true

          echo "Waiting for webhook server to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=webhook-server -A 2>/dev/null || \
            echo "::notice::Webhook server not found or not ready, continuing anyway"
          sleep 5

          # Try to apply sample configs with retry
          tag_success=false
          for i in 1 2 3 4 5; do
            if kubectl apply --server-side --force-conflicts -k config/samples/ 2>&1; then
              tag_success=true
              break
            fi
            echo "Attempt $i failed, waiting before retry..."
            sleep 10
          done
          echo "tag_success=${tag_success}" >> $GITHUB_OUTPUT
          if [ "$tag_success" = "false" ]; then
            echo "::warning::Tag branch samples failed to apply, skipping tag comparison"
            exit 0
          fi

          kubectl wait --for=condition=Ready roledefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some RoleDefinitions not fully reconciled"
          kubectl wait --for=condition=Ready binddefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some BindDefinitions not fully reconciled"

          bash ../pr-branch/hack/ci/capture-operator-output.sh /tmp/tag-output

          kubectl delete -k config/samples/ --ignore-not-found --timeout=60s 2>/dev/null || true
          echo "Waiting for CRs to be fully deleted..."
          kubectl wait --for=delete roledefinition --all --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete binddefinition --all --timeout=60s 2>/dev/null || true
          kubectl wait --for=delete webhookauthorizer --all --timeout=60s 2>/dev/null || true
          make undeploy 2>/dev/null || true

          echo "Tag branch (${{ steps.latest-tag.outputs.tag }}) outputs captured"

      # =====================================================================
      #  PR branch
      # =====================================================================
      - name: Generate outputs from PR branch
        id: pr-output
        run: |
          cd pr-branch

          make docker-build IMG=auth-operator:pr
          kind load docker-image auth-operator:pr --name output-delta

          make install

          make deploy IMG=auth-operator:pr
          echo "Waiting for operator to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=controller-manager -A 2>/dev/null || \
            echo "::warning::Could not verify controller-manager readiness, continuing anyway"

          echo "Waiting for webhook server to be ready..."
          kubectl wait --for=condition=available --timeout=120s deployment -l control-plane=webhook-server -A 2>/dev/null || \
            echo "::warning::Could not verify webhook-server readiness, continuing anyway"
          sleep 5

          # Apply sample configs with retry (webhook may need additional time to be fully ready)
          for i in 1 2 3 4 5; do
            if kubectl apply --server-side --force-conflicts -k config/samples/ 2>&1; then
              echo "Samples applied successfully"
              break
            fi
            echo "Attempt $i failed, waiting before retry..."
            sleep 10
          done

          kubectl wait --for=condition=Ready roledefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some RoleDefinitions not fully reconciled"
          kubectl wait --for=condition=Ready binddefinition --all --timeout=120s 2>/dev/null || echo "::notice::Some BindDefinitions not fully reconciled"

          bash hack/ci/capture-operator-output.sh /tmp/pr-output

          echo "PR branch outputs captured"

      # =====================================================================
      #  Collect debug artifacts
      # =====================================================================
      - name: Collect controller logs
        if: always()
        run: |
          mkdir -p /tmp/controller-logs

          echo "Collecting controller logs..."
          for ns in auth-operator-system kube-system default; do
            kubectl logs -n $ns -l control-plane=controller-manager --tail=5000 > /tmp/controller-logs/${ns}-controller.log 2>/dev/null || true
            kubectl logs -n $ns -l app.kubernetes.io/name=auth-operator --tail=5000 >> /tmp/controller-logs/${ns}-controller.log 2>/dev/null || true
          done

          # Get webhook server logs
          for ns in auth-operator-system kube-system default; do
            kubectl logs -n $ns -l control-plane=webhook-server --tail=5000 > /tmp/controller-logs/${ns}-webhook.log 2>/dev/null || true
          done

          # Get all events
          kubectl get events -A --sort-by='.lastTimestamp' > /tmp/controller-logs/all-events.txt 2>/dev/null || true

          # Get pod statuses
          kubectl get pods -A > /tmp/controller-logs/all-pods.txt 2>/dev/null || true

          # Get CRD statuses (raw, for debugging)
          kubectl get roledefinitions -A -o yaml > /tmp/controller-logs/roledefinitions.yaml 2>/dev/null || true
          kubectl get binddefinitions -A -o yaml > /tmp/controller-logs/binddefinitions.yaml 2>/dev/null || true

          echo "Controller logs collected"

      - name: Extract errors from logs
        if: always()
        id: extract-errors
        run: |
          mkdir -p /tmp/error-summary

          ERROR_LOG="/tmp/error-summary/errors.txt"
          echo "# Error Summary from Controller Logs" > "$ERROR_LOG"
          echo "" >> "$ERROR_LOG"

          for log in /tmp/controller-logs/*.log; do
            if [ -f "$log" ] && [ -s "$log" ]; then
              log_name=$(basename "$log")
              errors=$(grep -iE '("level":"error|ERROR|\serror\s|\[error\]|level=error|panic:|PANIC|failed|failure|Failed|Failure)' "$log" 2>/dev/null | head -50 || true)
              if [ -n "$errors" ]; then
                echo "## $log_name" >> "$ERROR_LOG"
                echo '```' >> "$ERROR_LOG"
                echo "$errors" >> "$ERROR_LOG"
                echo '```' >> "$ERROR_LOG"
                echo "" >> "$ERROR_LOG"
              fi
            fi
          done

          echo "## Warning/Error Events" >> "$ERROR_LOG"
          echo '```' >> "$ERROR_LOG"
          grep -iE '(Warning|Error|Failed|BackOff)' /tmp/controller-logs/all-events.txt 2>/dev/null | tail -30 >> "$ERROR_LOG" || echo "No warning events found" >> "$ERROR_LOG"
          echo '```' >> "$ERROR_LOG"
          echo "" >> "$ERROR_LOG"

          echo "## CRD Conditions (non-Ready)" >> "$ERROR_LOG"
          echo '```yaml' >> "$ERROR_LOG"
          for crd in roledefinitions binddefinitions; do
            if [ -f "/tmp/controller-logs/${crd}.yaml" ]; then
              yq '.items[] | select(.status.conditions != null) | select(.status.conditions[] | select(.status != "True")) | {"name": .metadata.name, "conditions": .status.conditions}' "/tmp/controller-logs/${crd}.yaml" 2>/dev/null >> "$ERROR_LOG" || true
            fi
          done
          echo '```' >> "$ERROR_LOG"

          error_count=$(grep -cE '(ERROR|error|panic|failed|failure|Warning)' "$ERROR_LOG" 2>/dev/null || echo "0")
          if [ "$error_count" -gt 5 ]; then
            echo "has_errors=true" >> $GITHUB_OUTPUT
          else
            echo "has_errors=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload controller logs
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: controller-logs
          path: /tmp/controller-logs/
          retention-days: 7

      - name: Upload error summary
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: error-summary
          path: /tmp/error-summary/
          retention-days: 7

      - name: Upload output artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: output-delta-artifacts
          path: |
            /tmp/main-output/
            /tmp/pr-output/
            /tmp/tag-output/
          retention-days: 7

      # =====================================================================
      #  Generate diff and comment on PR
      # =====================================================================
      - name: Generate diff
        id: diff
        run: |
          mkdir -p /tmp/diff-output/main /tmp/diff-output/tag

          if [ "$MAIN_FALLBACK" = "true" ]; then
            echo "main_fallback=true" >> $GITHUB_OUTPUT
          else
            echo "main_fallback=false" >> $GITHUB_OUTPUT
          fi

          # Generate per-resource diff files (main vs PR) — separate directory
          for resource in clusterroles roles clusterrolebindings rolebindings serviceaccounts; do
            diff -u /tmp/main-output/$resource.yaml /tmp/pr-output/$resource.yaml > /tmp/diff-output/main/$resource.diff 2>&1 || true
          done

          # CRD status diffs (main vs PR)
          for resource in roledefinitions-status binddefinitions-status; do
            if [ -f "/tmp/main-output/$resource.yaml" ] && [ -f "/tmp/pr-output/$resource.yaml" ]; then
              diff -u /tmp/main-output/$resource.yaml /tmp/pr-output/$resource.yaml > /tmp/diff-output/main/$resource.diff 2>&1 || true
            fi
          done

          # Tag diffs (tag vs PR) — separate directory
          if [ -d "/tmp/tag-output" ] && [ "${{ steps.tag-output.outputs.tag_success }}" = "true" ]; then
            for resource in clusterroles roles clusterrolebindings rolebindings serviceaccounts; do
              diff -u /tmp/tag-output/$resource.yaml /tmp/pr-output/$resource.yaml > /tmp/diff-output/tag/$resource.diff 2>&1 || true
            done

            for resource in roledefinitions-status binddefinitions-status; do
              if [ -f "/tmp/tag-output/$resource.yaml" ] && [ -f "/tmp/pr-output/$resource.yaml" ]; then
                diff -u /tmp/tag-output/$resource.yaml /tmp/pr-output/$resource.yaml > /tmp/diff-output/tag/$resource.diff 2>&1 || true
              fi
            done

            echo "has_tag_diff=true" >> $GITHUB_OUTPUT
          else
            echo "has_tag_diff=false" >> $GITHUB_OUTPUT
          fi

          # Combined diff for backward compatibility
          cat /tmp/diff-output/main/*.diff /tmp/diff-output/tag/*.diff > /tmp/diff-output/full-diff.txt 2>/dev/null || true

          # Determine if there are meaningful differences
          if [ "$MAIN_FALLBACK" = "true" ]; then
            echo "has_diff=true" >> $GITHUB_OUTPUT
          elif diff -q /tmp/main-output /tmp/pr-output > /dev/null 2>&1; then
            echo "has_diff=false" >> $GITHUB_OUTPUT
          else
            echo "has_diff=true" >> $GITHUB_OUTPUT
          fi

      - name: Upload diff artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: diff-output
          path: /tmp/diff-output/
          retention-days: 7

      - name: Comment PR with delta
        if: steps.diff.outputs.has_diff == 'true' || steps.extract-errors.outputs.has_errors == 'true'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');

            const MAX_COMMENT_LENGTH = 65000; // GitHub limit is 65536, leave margin
            // Marker prefix used to identify and update/delete our comments
            const MARKER = '<!-- output-delta:';

            function truncate(text, limit) {
              if (text.length <= limit) return text;
              const truncMsg = '\n... (truncated, ' + text.length + ' chars total — see uploaded artifacts for full diff)';
              return text.substring(0, limit - truncMsg.length) + truncMsg;
            }

            function readDiff(dir, filename) {
              try {
                const content = fs.readFileSync('/tmp/diff-output/' + dir + '/' + filename, 'utf8');
                if (content.trim() && content.includes('@@')) {
                  return content;
                }
              } catch (e) { /* file doesn't exist */ }
              return '';
            }

            function readFile(filepath) {
              try {
                const content = fs.readFileSync(filepath, 'utf8');
                return content.trim() || '';
              } catch (e) { return ''; }
            }

            const resources = [
              ['ClusterRoles', 'clusterroles.diff'],
              ['Roles', 'roles.diff'],
              ['ClusterRoleBindings', 'clusterrolebindings.diff'],
              ['RoleBindings', 'rolebindings.diff'],
              ['ServiceAccounts', 'serviceaccounts.diff'],
              ['RoleDefinitions Status', 'roledefinitions-status.diff'],
              ['BindDefinitions Status', 'binddefinitions-status.diff']
            ];

            const mainFallback = '${{ steps.diff.outputs.main_fallback }}' === 'true';
            const hasErrors = '${{ steps.extract-errors.outputs.has_errors }}' === 'true';
            const hasTagDiff = '${{ steps.diff.outputs.has_tag_diff }}' === 'true';
            const latestTag = '${{ steps.latest-tag.outputs.tag }}';

            // Fetch all existing bot comments once
            const { data: allComments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            const botComments = allComments.filter(c => c.user.type === 'Bot' && c.body.includes(MARKER));

            // Helper: upsert or create a comment identified by a unique marker tag
            async function upsertComment(tag, body) {
              const markerTag = MARKER + tag + ' -->';
              body = markerTag + '\n' + body;
              if (body.length > MAX_COMMENT_LENGTH) {
                body = truncate(body, MAX_COMMENT_LENGTH);
              }
              const existing = botComments.find(c => c.body.includes(markerTag));
              if (existing) {
                await github.rest.issues.updateComment({
                  owner: context.repo.owner, repo: context.repo.repo,
                  comment_id: existing.id, body
                });
              } else {
                await github.rest.issues.createComment({
                  owner: context.repo.owner, repo: context.repo.repo,
                  issue_number: context.issue.number, body
                });
              }
            }

            // Helper: delete stale comments for tags no longer needed
            async function deleteComment(tag) {
              const markerTag = MARKER + tag + ' -->';
              const existing = botComments.find(c => c.body.includes(markerTag));
              if (existing) {
                await github.rest.issues.deleteComment({
                  owner: context.repo.owner, repo: context.repo.repo,
                  comment_id: existing.id
                });
              }
            }

            // ── Build sections for each resource type ──
            const sections = []; // { name, tag, body }
            for (const [name, file] of resources) {
              const tag = file.replace('.diff', '');
              const mainDiff = readDiff('main', file);
              const tagDiff = (hasTagDiff && latestTag) ? readDiff('tag', file) : '';
              if (!mainDiff && !tagDiff) continue;

              let section = '### :package: ' + name + '\n\n';
              if (mainDiff) {
                section += '<details>\n<summary>Changes from <code>main</code></summary>\n\n```diff\n' + mainDiff + '\n```\n\n</details>\n\n';
              }
              if (tagDiff) {
                section += '<details>\n<summary>Changes from <code>' + latestTag + '</code></summary>\n\n```diff\n' + tagDiff + '\n```\n\n</details>\n\n';
              }
              sections.push({ name, tag, body: section });
            }

            // ── Build header (always included in the first comment) ──
            let header = '## :bar_chart: Output Delta Report\n\n';
            if (mainFallback) {
              header += '> :warning: **Note:** Main branch samples failed to apply (likely due to schema changes).\n' +
                '> PR branch samples were used as baseline, so no meaningful diff is shown.\n' +
                '> This typically happens when sample files are updated with new required fields.\n\n';
            }
            header += 'Generated RBAC resources from `config/samples/` compared across branches.\n\n';

            if (sections.length === 0) {
              header += ':white_check_mark: No resource changes detected vs `main`.\n';
            }

            // Append metrics to header (small payload)
            const metrics = readFile('/tmp/pr-output/metrics.txt');
            if (metrics && !metrics.startsWith('# No metrics')) {
              header += '### Prometheus Metrics (PR branch)\n\n';
              header += '<details>\n<summary>:chart_with_upwards_trend: auth_operator_* metrics</summary>\n\n```\n' + metrics + '\n```\n\n</details>\n\n';
            }

            // Append errors to header
            if (hasErrors) {
              const errorSummary = readFile('/tmp/error-summary/errors.txt');
              if (errorSummary) {
                header += '---\n\n## :warning: Controller Logs\n\n' +
                  '<details>\n<summary>Errors/Warnings Found in Logs (click to expand)</summary>\n\n' +
                  errorSummary + '\n\n</details>\n\n';
              }
            }

            // ── Pack sections into as few comments as possible (≤65k each) ──
            // Marker overhead: "<!-- output-delta:partN -->\n" ≈ 35 chars
            const MARKER_OVERHEAD = 50;
            const comments = []; // [{ tag, body }]
            let currentBody = header;
            let currentPart = 1;

            for (const section of sections) {
              if (currentBody.length + section.body.length + MARKER_OVERHEAD > MAX_COMMENT_LENGTH && currentBody !== header) {
                // Flush current comment
                comments.push({ tag: 'part' + currentPart, body: currentBody });
                currentPart++;
                currentBody = '## :bar_chart: Output Delta Report (cont.)\n\n';
              }
              // If a single section alone exceeds the limit, truncate it
              if (currentBody.length + section.body.length + MARKER_OVERHEAD > MAX_COMMENT_LENGTH) {
                const available = MAX_COMMENT_LENGTH - currentBody.length - MARKER_OVERHEAD;
                currentBody += truncate(section.body, Math.max(available, 500));
              } else {
                currentBody += section.body;
              }
            }
            // Flush last comment
            comments.push({ tag: 'part' + currentPart, body: currentBody });

            // ── Post / update / delete comments ──
            for (const comment of comments) {
              await upsertComment(comment.tag, comment.body);
            }

            // Delete stale part comments from previous runs that are no longer needed
            for (let i = currentPart + 1; i <= 10; i++) {
              await deleteComment('part' + i);
            }

      - name: Comment PR - no changes
        if: steps.diff.outputs.has_diff == 'false' && steps.diff.outputs.main_fallback != 'true'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const MARKER = '<!-- output-delta:';

            const { data: allComments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            const botComments = allComments.filter(c => c.user.type === 'Bot' && c.body.includes(MARKER));

            // Delete all previous part comments except part1
            for (const c of botComments) {
              if (!c.body.includes(MARKER + 'part1 -->')) {
                await github.rest.issues.deleteComment({
                  owner: context.repo.owner, repo: context.repo.repo,
                  comment_id: c.id
                });
              }
            }

            // Upsert part1 as the no-changes summary
            const markerTag = MARKER + 'part1 -->';
            const body = markerTag + '\n## :bar_chart: Output Delta Report\n\n' +
              ':white_check_mark: No changes detected in generated RBAC resources.\n\n' +
              'The sample configurations in `config/samples/` produce identical output on both main and this PR.\n';

            const existing = botComments.find(c => c.body.includes(markerTag));
            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner, repo: context.repo.repo,
                comment_id: existing.id, body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner, repo: context.repo.repo,
                issue_number: context.issue.number, body
              });
            }

      - name: Cleanup
        if: always()
        run: kind delete cluster --name output-delta
